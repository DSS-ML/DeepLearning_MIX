{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586cfcda",
   "metadata": {},
   "source": [
    "- https://aistudio.google.com/prompts/new_chat\n",
    "- https://ollama.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9719cc53",
   "metadata": {},
   "source": [
    "# Ollama to analyze text and categorize whether it's AI-related, sorting into development or application categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e889336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Text Analyzer - Type 'exit' to quit\n",
      "\n",
      "Enter text to analyze: Much of the recent success of Artificial Intelligence (AI) has been spurred on by impressive achievements within a broader family of machine learning methods, commonly referred to as Deep Learning (DL). This paper provides insights on the diffusion and impact of DL in science. Through a Natural Language Processing (NLP) approach on the arXiv.org publication corpus, we delineate the emerging DL technology and identify a list of relevant search terms. These search terms allow us to retrieve DL-related publications from Web of Science across all sciences. Based on that sample, we document the DL diffusion process in the scientific system. We find i) an exponential growth in the adoption of DL as a research tool across all sciences and all over the world, ii) regional differentiation in DL application domains, and iii) a transition from interdisciplinary DL applications to disciplinary research within application domains. In a second step, we investigate how the adoption of DL methods affects scientific development. Therefore, we empirically assess how DL adoption relates to re-combinatorial novelty and scientific impact in the health sciences. We find that DL adoption is negatively correlated with re-combinatorial novelty, but positively correlated with expectation as well as variance of citation performance. Our findings suggest that DL does not (yet?) work as an autopilot to navigate complex knowledge landscapes and overthrow their structure. However, the 'DL principle' qualifies for its versatility as the nucleus of a general scientific method that advances science in a measurable way. \n",
      "\n",
      "Analysis Results:\n",
      "AI Related: YES\n",
      "Category: Application\n",
      "Field: Healthcare (With Nlp Underpinnings)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Enter text to analyze: quit\n",
      "Please enter at least 20 characters\n",
      "\n",
      "Enter text to analyze: exit\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"mannix/gemma2-9b-simpo\"\n",
    "SYSTEM_PROMPT = \"\"\"Analyze if the text is about AI. If yes, categorize as either:\n",
    "- Development (new AI tech/architectures)\n",
    "- Application (using existing AI in domains)\n",
    "and specify the field (e.g., NLP, Healthcare). \n",
    "\n",
    "Respond STRICTLY in format: yes|category|field OR no||\"\"\"\n",
    "\n",
    "def analyze_text(text):\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": f\"TEXT: {text}\"}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        result = response['message']['content'].strip().lower()\n",
    "        is_ai, category, field = result.split('|')\n",
    "        \n",
    "        print(\"\\nAnalysis Results:\")\n",
    "        print(f\"AI Related: {'YES' if is_ai == 'yes' else 'NO'}\")\n",
    "        if is_ai == 'yes':\n",
    "            print(f\"Category: {category.title()}\")\n",
    "            print(f\"Field: {field.title()}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "\n",
    "# Simple text input loop\n",
    "print(\"AI Text Analyzer - Type 'exit' to quit\\n\")\n",
    "while True:\n",
    "    text = input(\"Enter text to analyze: \").strip()\n",
    "    \n",
    "    if text.lower() == 'exit':\n",
    "        break\n",
    "        \n",
    "    if len(text) < 20:\n",
    "        print(\"Please enter at least 20 characters\\n\")\n",
    "        continue\n",
    "        \n",
    "    analyze_text(text)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35717037",
   "metadata": {},
   "source": [
    "# Which AI chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6fe4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext\n",
    "import threading\n",
    "\n",
    "class AIClassifierApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        root.title(\"Advanced AI Text Analyzer\")\n",
    "        root.geometry(\"720x580\")\n",
    "        \n",
    "        # Configure style\n",
    "        self.style = ttk.Style()\n",
    "        self.style.configure('TFrame', background='#f0f0f0')\n",
    "        self.style.configure('TLabel', background='#f0f0f0')\n",
    "        self.style.configure('Header.TLabel', font=('Helvetica', 14, 'bold'))\n",
    "        \n",
    "        # Create main container\n",
    "        self.main_frame = ttk.Frame(root, padding=20)\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Create widgets\n",
    "        self.create_widgets()\n",
    "        \n",
    "        # Configure grid weights\n",
    "        self.main_frame.columnconfigure(0, weight=1)\n",
    "        self.main_frame.rowconfigure(3, weight=1)\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # Header\n",
    "        header = ttk.Label(\n",
    "            self.main_frame,\n",
    "            text=\"AI Text Analysis System\",\n",
    "            style='Header.TLabel'\n",
    "        )\n",
    "        header.grid(row=0, column=0, pady=(0, 20))\n",
    "        \n",
    "        # Instructions\n",
    "        instructions = ttk.Label(\n",
    "            self.main_frame,\n",
    "            text=\"Enter text to analyze AI relevance, category, and field:\",\n",
    "            wraplength=600\n",
    "        )\n",
    "        instructions.grid(row=1, column=0, pady=(0, 15))\n",
    "        \n",
    "        # Text input\n",
    "        self.text_input = scrolledtext.ScrolledText(\n",
    "            self.main_frame,\n",
    "            wrap=tk.WORD,\n",
    "            height=10,\n",
    "            font=('Helvetica', 11),\n",
    "            padx=10,\n",
    "            pady=10\n",
    "        )\n",
    "        self.text_input.grid(row=2, column=0, sticky='nsew')\n",
    "        \n",
    "        # Button frame\n",
    "        button_frame = ttk.Frame(self.main_frame)\n",
    "        button_frame.grid(row=3, column=0, pady=15)\n",
    "        \n",
    "        # Analyze button\n",
    "        self.analyze_btn = ttk.Button(\n",
    "            button_frame,\n",
    "            text=\"Analyze Text\",\n",
    "            command=self.start_analysis_thread\n",
    "        )\n",
    "        self.analyze_btn.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # Result frame\n",
    "        self.result_frame = ttk.Frame(self.main_frame)\n",
    "        self.result_frame.grid(row=4, column=0, sticky='nsew')\n",
    "\n",
    "    def start_analysis_thread(self):\n",
    "        text = self.text_input.get(\"1.0\", tk.END).strip()\n",
    "        if len(text) < 30:\n",
    "            self.show_error(\"Please enter at least 30 characters\")\n",
    "            return\n",
    "            \n",
    "        self.analyze_btn.config(state=tk.DISABLED, text=\"Analyzing...\")\n",
    "        thread = threading.Thread(target=self.analyze_text, args=(text,))\n",
    "        thread.start()\n",
    "\n",
    "    def analyze_text(self, text):\n",
    "        system_prompt = \"\"\"Analyze the text through this decision tree:\n",
    "\n",
    "1. AI Relevance:\n",
    "- Explicit mention of AI/ML/DL/NN/LLM?\n",
    "- Topics: neural networks, machine learning, deep learning, AI models, AI applications\n",
    "- Related hardware/ethics? If no â†’ Respond \"no||\"\n",
    "\n",
    "2. Category:\n",
    "- Development: New architectures, model optimization, training techniques\n",
    "- Application: Implementing existing AI in specific domains\n",
    "\n",
    "3. Field:\n",
    "Computer Vision, NLP, Robotics, Healthcare, Finance, Education, \n",
    "Cybersecurity, Climate Science, Manufacturing, Entertainment, \n",
    "Transportation, Ethics/Governance, General AI, Other\n",
    "\n",
    "Response format STRICT:\n",
    "[yes/no]|[development/application]|[Field]\n",
    "Examples:\n",
    "\"yes|development|Natural Language Processing\"\n",
    "\"no||\" \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model='mannix/gemma2-9b-simpo',\n",
    "                options={'temperature': 0},\n",
    "                messages=[\n",
    "                    {'role': 'system', 'content': system_prompt},\n",
    "                    {'role': 'user', 'content': f\"Text:\\n{text}\"}\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            result = response['message']['content'].strip().lower()\n",
    "            parts = result.split('|')\n",
    "            \n",
    "            if len(parts) != 3:\n",
    "                raise ValueError(\"Invalid response format\")\n",
    "                \n",
    "            parsed = {\n",
    "                'is_ai': parts[0] == 'yes',\n",
    "                'category': parts[1] if parts[1] else None,\n",
    "                'field': parts[2] if parts[2] else None\n",
    "            }\n",
    "            \n",
    "            self.root.after(0, self.show_analysis_result, parsed)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.root.after(0, self.show_error, f\"Analysis Error: {str(e)}\")\n",
    "            \n",
    "        finally:\n",
    "            self.root.after(0, self.analyze_btn.config, \n",
    "                {'state': tk.NORMAL, 'text': \"Analyze Text\"})\n",
    "\n",
    "    def show_analysis_result(self, result):\n",
    "        # Clear previous results\n",
    "        for widget in self.result_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        \n",
    "        # Main status\n",
    "        status_text = \"AI-Related: \" + (\"Yes\" if result['is_ai'] else \"No\")\n",
    "        status_color = \"#2ecc71\" if result['is_ai'] else \"#e74c3c\"\n",
    "        status_label = ttk.Label(\n",
    "            self.result_frame,\n",
    "            text=status_text,\n",
    "            font=('Helvetica', 12, 'bold'),\n",
    "            foreground=status_color\n",
    "        )\n",
    "        status_label.pack(pady=5)\n",
    "        \n",
    "        if result['is_ai']:\n",
    "            # Category\n",
    "            cat_text = f\"Category: {result['category'].title() if result['category'] else 'Unspecified'}\"\n",
    "            cat_label = ttk.Label(\n",
    "                self.result_frame,\n",
    "                text=cat_text,\n",
    "                font=('Helvetica', 11)\n",
    "            )\n",
    "            cat_label.pack(pady=2)\n",
    "            \n",
    "            # Field\n",
    "            field_text = f\"Field: {result['field'].title() if result['field'] else 'Unspecified'}\"\n",
    "            field_label = ttk.Label(\n",
    "                self.result_frame,\n",
    "                text=field_text,\n",
    "                font=('Helvetica', 11, 'italic')\n",
    "            )\n",
    "            field_label.pack(pady=2)\n",
    "            \n",
    "            # Add explanation\n",
    "            explanation = self.get_explanation_text(result)\n",
    "            expl_label = ttk.Label(\n",
    "                self.result_frame,\n",
    "                text=explanation,\n",
    "                wraplength=600,\n",
    "                foreground=\"#34495e\"\n",
    "            )\n",
    "            expl_label.pack(pady=10)\n",
    "\n",
    "    def show_error(self, message):\n",
    "        for widget in self.result_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "            \n",
    "        error_label = ttk.Label(\n",
    "            self.result_frame,\n",
    "            text=message,\n",
    "            foreground=\"#e74c3c\"\n",
    "        )\n",
    "        error_label.pack()\n",
    "\n",
    "    def get_explanation_text(self, result):\n",
    "        explanations = {\n",
    "            'development': {\n",
    "                'computer vision': \"Focuses on new architectures or improvements in visual processing systems\",\n",
    "                'natural language processing': \"Involves novel approaches to language understanding/generation\",\n",
    "                'general ai': \"Addresses fundamental advancements in AI capabilities\"\n",
    "            },\n",
    "            'application': {\n",
    "                'healthcare': \"Applies existing AI technologies to medical diagnosis/treatment\",\n",
    "                'finance': \"Implements AI for market analysis or risk assessment\",\n",
    "                'manufacturing': \"Utilizes AI for process optimization/quality control\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        base_text = \"This text discusses \"\n",
    "        if result['category'] and result['field']:\n",
    "            key = explanations.get(result['category'], {}).get(result['field'].lower(), \"\")\n",
    "            if key:\n",
    "                return base_text + key\n",
    "        return \"AI-related content analysis complete\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = AIClassifierApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab7b765",
   "metadata": {},
   "source": [
    "# Document chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb37369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext, filedialog\n",
    "import threading\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "\n",
    "class DocumentChatbot:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        root.title(\"Document Chatbot\")\n",
    "        root.geometry(\"800x600\")\n",
    "        \n",
    "        self.document_text = \"\"\n",
    "        self.chat_history = []\n",
    "        \n",
    "        # Configure style\n",
    "        self.style = ttk.Style()\n",
    "        self.style.configure('TFrame', background='#f0f0f0')\n",
    "        self.style.configure('TLabel', background='#f0f0f0')\n",
    "        \n",
    "        # Create main container\n",
    "        self.main_frame = ttk.Frame(root, padding=15)\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        self.create_widgets()\n",
    "        \n",
    "    def create_widgets(self):\n",
    "        # Document upload section\n",
    "        doc_frame = ttk.Frame(self.main_frame)\n",
    "        doc_frame.pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        ttk.Button(doc_frame, text=\"Upload Document\", \n",
    "                 command=self.upload_document).pack(side=tk.LEFT)\n",
    "        \n",
    "        self.doc_label = ttk.Label(doc_frame, text=\"No document loaded\")\n",
    "        self.doc_label.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # Chat history\n",
    "        self.chat_display = scrolledtext.ScrolledText(\n",
    "            self.main_frame,\n",
    "            wrap=tk.WORD,\n",
    "            state='disabled',\n",
    "            font=('Helvetica', 11)\n",
    "        )\n",
    "        self.chat_display.pack(fill=tk.BOTH, expand=True, pady=10)\n",
    "        \n",
    "        # Input area\n",
    "        input_frame = ttk.Frame(self.main_frame)\n",
    "        input_frame.pack(fill=tk.X)\n",
    "        \n",
    "        self.user_input = ttk.Entry(input_frame, font=('Helvetica', 11))\n",
    "        self.user_input.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)\n",
    "        self.user_input.bind(\"<Return>\", lambda e: self.send_message())\n",
    "        \n",
    "        ttk.Button(input_frame, text=\"Send\", \n",
    "                 command=self.send_message).pack(side=tk.LEFT)\n",
    "    \n",
    "    def upload_document(self):\n",
    "        filetypes = (\n",
    "            ('Text files', '*.txt'),\n",
    "            ('PDF files', '*.pdf'),\n",
    "            ('Word documents', '*.docx'),\n",
    "            ('All files', '*.*')\n",
    "        )\n",
    "        \n",
    "        files = filedialog.askopenfilenames(title=\"Select documents\", filetypes=filetypes)\n",
    "        if files:\n",
    "            self.process_documents(files)\n",
    "    \n",
    "    def process_documents(self, file_paths):\n",
    "        self.document_text = \"\"\n",
    "        for path in file_paths:\n",
    "            if path.endswith('.pdf'):\n",
    "                reader = PdfReader(path)\n",
    "                text = \" \".join([page.extract_text() for page in reader.pages])\n",
    "            elif path.endswith('.docx'):\n",
    "                doc = Document(path)\n",
    "                text = \" \".join([para.text for para in doc.paragraphs])\n",
    "            else:  # Assume txt file\n",
    "                with open(path, 'r') as f:\n",
    "                    text = f.read()\n",
    "            \n",
    "            self.document_text += text + \"\\n\\n\"\n",
    "        \n",
    "        self.doc_label.config(text=f\"Loaded {len(file_paths)} documents\")\n",
    "        self.add_to_chat(\"System\", \"Documents processed and ready for questions\")\n",
    "    \n",
    "    def send_message(self):\n",
    "        question = self.user_input.get().strip()\n",
    "        if not question:\n",
    "            return\n",
    "            \n",
    "        self.user_input.delete(0, tk.END)\n",
    "        self.add_to_chat(\"You\", question)\n",
    "        \n",
    "        if not self.document_text:\n",
    "            self.add_to_chat(\"Bot\", \"Please upload documents first!\")\n",
    "            return\n",
    "            \n",
    "        threading.Thread(target=self.process_question, args=(question,)).start()\n",
    "    \n",
    "    def process_question(self, question):\n",
    "        prompt = f\"\"\"Answer based on the provided documents. If unsure, say so.\n",
    "\n",
    "Documents:\n",
    "{self.document_text[:10000]}  # Limit context length\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model='mannix/gemma2-9b-simpo',\n",
    "                messages=[{'role': 'user', 'content': prompt}],\n",
    "                options={'temperature': 0.3}\n",
    "            )\n",
    "            \n",
    "            answer = response['message']['content'].strip()\n",
    "            self.add_to_chat(\"Bot\", answer)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.add_to_chat(\"Error\", str(e))\n",
    "    \n",
    "    def add_to_chat(self, sender, message):\n",
    "        self.chat_display.config(state='normal')\n",
    "        self.chat_display.insert(tk.END, f\"{sender}: {message}\\n\\n\")\n",
    "        self.chat_display.yview(tk.END)\n",
    "        self.chat_display.config(state='disabled')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = DocumentChatbot(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103294c4",
   "metadata": {},
   "source": [
    "# AI Expert with gemini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44e12959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Expert System Initialized. Type 'exit' to end the session.\n",
      "\n",
      "You: What is AI?\n",
      "\n",
      "Expert: \"AI,\" or Artificial Intelligence, is a broad field aiming to create machines capable of performing tasks that typically require human intelligence.  Think of things like problem-solving, learning, decision-making, and understanding language.  It's a bit like teaching a computer to think and act more like a human.\n",
      "\n",
      "There are different ways to achieve this.  One common approach is **rule-based AI**, where we explicitly program all the rules and logic.  For example, a spam filter might be programmed to flag emails containing certain keywords.  This works well for simple tasks, but becomes very complex for more nuanced situations.\n",
      "\n",
      "More advanced AI relies on **machine learning**, where instead of programming explicit rules, we feed the computer lots of data and let it learn the patterns itself. Imagine teaching a child to recognize a cat â€“ you wouldn't give them a strict definition, but rather show them many pictures of cats.  Machine learning algorithms do something similar.  A subset of machine learning called **deep learning** uses complex, layered \"neural networks\" inspired by the human brain, allowing the AI to learn even more intricate patterns.  This is how systems like self-driving cars learn to navigate complex environments.\n",
      "\n",
      "**Natural Language Processing (NLP)** is another branch of AI focused on enabling computers to understand and generate human language.  Think of virtual assistants like Siri or Google Assistant, or translation tools.  **Computer vision** aims to give computers the ability to \"see\" and interpret images and videos, like facial recognition systems or medical image analysis tools.  **Reinforcement learning** is about training AI agents to make decisions in an environment to maximize a reward, similar to how we train dogs with treats.  This is used in areas like robotics and game playing.\n",
      "\n",
      "Building AI systems comes with challenges.  We need massive amounts of data, powerful computers, and sophisticated algorithms.  There are also ethical considerations.  For example, biased data can lead to biased AI systems, and we need to be careful about how we deploy AI in areas like hiring or law enforcement to avoid perpetuating or creating unfair practices.  Ensuring AI safety is also crucial, as highly capable AI systems could pose unforeseen risks if not developed and managed responsibly.\n",
      "\n",
      "So, in short, AI is about creating intelligent machines.  It's a rapidly evolving field with huge potential to transform many aspects of our lives, but it's important to develop and use it responsibly, considering both its technical challenges and its ethical implications.\n",
      "\n",
      "\n",
      "You: Can you write a python code on how to use scrape linkedin?\n",
      "\n",
      "Expert: Scraping LinkedIn is a complex issue with significant ethical and legal implications.  LinkedIn's terms of service explicitly prohibit scraping, and violating these terms can lead to account suspension or legal action.  Therefore, I cannot provide code that directly scrapes LinkedIn data.  It's crucial to respect website terms of service and user privacy.\n",
      "\n",
      "However, I can offer some general information about web scraping and alternative approaches to gathering LinkedIn data that comply with their terms of service.\n",
      "\n",
      "**General Web Scraping Concepts (for educational purposes only):**\n",
      "\n",
      "Web scraping typically involves using libraries like `requests` to fetch the HTML content of a webpage and `BeautifulSoup` to parse that content and extract specific data.  Here's a very basic example of how these libraries might be used (again, not for LinkedIn):\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def scrape_example_website(url):\n",
      "    try:\n",
      "        response = requests.get(url)\n",
      "        response.raise_for_status() # Raise an exception for bad status codes\n",
      "\n",
      "        soup = BeautifulSoup(response.content, 'html.parser')\n",
      "\n",
      "        # Example: Extract all link URLs\n",
      "        links = [link.get('href') for link in soup.find_all('a')]\n",
      "        return links\n",
      "\n",
      "    except requests.exceptions.RequestException as e:\n",
      "        print(f\"Error fetching URL: {e}\")\n",
      "        return None\n",
      "\n",
      "# Example usage (replace with a different website URL)\n",
      "links = scrape_example_website(\"https://www.example.com\")\n",
      "if links:\n",
      "    print(links)\n",
      "```\n",
      "\n",
      "**LinkedIn's API and Official Data Access Methods:**\n",
      "\n",
      "The recommended way to access LinkedIn data is through their official API.  The LinkedIn API provides a legitimate and controlled way to access certain types of data, such as profile information, connections, and company updates.  However, access to the API is often restricted and requires approval from LinkedIn.  You'll need to review their developer documentation and apply for access if needed.\n",
      "\n",
      "**Other Ethical Data Collection Strategies:**\n",
      "\n",
      "* **Publicly available data:** Some LinkedIn data is publicly accessible without logging in.  You can access this information ethically, but be mindful of rate limiting and robots.txt rules.\n",
      "* **Data enrichment services:** Several third-party services offer data enrichment, which can supplement your existing data with information from LinkedIn (obtained through ethical means).\n",
      "* **Building your own network and requesting connections:**  Organically growing your network and directly requesting connections is the most ethical and sustainable way to gather relevant LinkedIn data.\n",
      "\n",
      "Remember, respecting website terms of service and user privacy is paramount.  Always prioritize ethical data collection methods and avoid any practices that could harm individuals or violate platform rules.  Using LinkedIn's official API or other approved methods is the best way to ensure you're accessing data responsibly.\n",
      "\n",
      "\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure the API\n",
    "genai.configure(api_key='AIzaSyDDk9FAIyzA4lH8Luduml-0Fp--_BK1VFk')\n",
    "\n",
    "# Configure model parameters\n",
    "generation_config = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "}\n",
    "\n",
    "# System instruction template\n",
    "EXPERT_PROFILE = \"\"\"You are an artificial intelligence expert with extensive experience in both research and practical applications. Your expertise includes:\n",
    "\n",
    "- Deep learning architectures and neural networks\n",
    "- Natural language processing and generation\n",
    "- Computer vision systems\n",
    "- Reinforcement learning frameworks\n",
    "- AI ethics and safety considerations\n",
    "\n",
    "When responding:\n",
    "1. Analyze the question's technical depth\n",
    "2. Adapt explanations to the user's apparent knowledge level\n",
    "3. Provide real-world examples and analogies\n",
    "4. Highlight potential implementation challenges\n",
    "5. Discuss ethical implications where relevant\n",
    "6. Maintain scientific accuracy while being accessible\"\"\"\n",
    "\n",
    "def initialize_chat():\n",
    "    \"\"\"Initialize the chat session with expert configuration\"\"\"\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-pro-latest\",\n",
    "        generation_config=generation_config,\n",
    "        system_instruction=EXPERT_PROFILE\n",
    "    )\n",
    "    return model.start_chat(history=[])\n",
    "\n",
    "def chat_interface():\n",
    "    \"\"\"Interactive chat interface\"\"\"\n",
    "    chat_session = initialize_chat()\n",
    "    print(\"\\nAI Expert System Initialized. Type 'exit' to end the session.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() in ['exit', 'quit']:\n",
    "                break\n",
    "                \n",
    "            # Send message and stream response\n",
    "            print(\"\\nExpert: \", end=\"\", flush=True)\n",
    "            response = chat_session.send_message(user_input)\n",
    "            \n",
    "            # Print formatted response\n",
    "            for chunk in response:\n",
    "                print(chunk.text, end=\"\", flush=True)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nSession ended by user.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10adb48",
   "metadata": {},
   "source": [
    "# AI Expert chatbot with gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45913221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext, messagebox, Menu\n",
    "import threading\n",
    "\n",
    "class GeminiChatApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        root.title(\"AI Expert Chatbot\")\n",
    "        root.geometry(\"800x600\")\n",
    "        \n",
    "        # Configure API\n",
    "        self.api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        self.chat_session = None\n",
    "        self.history = []\n",
    "        \n",
    "        # Create GUI\n",
    "        self.create_widgets()\n",
    "        self.create_menu()\n",
    "        \n",
    "        # Initialize model if API key exists\n",
    "        if self.api_key:\n",
    "            self.initialize_model()\n",
    "        else:\n",
    "            self.show_api_key_dialog()\n",
    "\n",
    "    def create_menu(self):\n",
    "        menu_bar = Menu(self.root)\n",
    "        self.root.config(menu=menu_bar)\n",
    "        \n",
    "        # Settings menu\n",
    "        settings_menu = Menu(menu_bar, tearoff=0)\n",
    "        menu_bar.add_cascade(label=\"Settings\", menu=settings_menu)\n",
    "        settings_menu.add_command(label=\"Set API Key\", command=self.show_api_key_dialog)\n",
    "        settings_menu.add_command(label=\"Clear History\", command=self.clear_history)\n",
    "\n",
    "    def create_widgets(self):\n",
    "        main_frame = ttk.Frame(self.root, padding=10)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Chat history\n",
    "        self.chat_display = scrolledtext.ScrolledText(\n",
    "            main_frame,\n",
    "            wrap=tk.WORD,\n",
    "            state='disabled',\n",
    "            font=('Helvetica', 11),\n",
    "            padx=10,\n",
    "            pady=10\n",
    "        )\n",
    "        self.chat_display.pack(fill=tk.BOTH, expand=True, pady=5)\n",
    "        \n",
    "        # Input area\n",
    "        input_frame = ttk.Frame(main_frame)\n",
    "        input_frame.pack(fill=tk.X, pady=10)\n",
    "        \n",
    "        self.user_input = ttk.Entry(\n",
    "            input_frame,\n",
    "            font=('Helvetica', 11)\n",
    "        )\n",
    "        self.user_input.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)\n",
    "        self.user_input.bind(\"<Return>\", lambda e: self.send_message())\n",
    "        \n",
    "        send_btn = ttk.Button(\n",
    "            input_frame,\n",
    "            text=\"Send\",\n",
    "            command=self.send_message\n",
    "        )\n",
    "        send_btn.pack(side=tk.LEFT)\n",
    "\n",
    "    def initialize_model(self):\n",
    "        try:\n",
    "            genai.configure(api_key=self.api_key)\n",
    "            \n",
    "            generation_config = {\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.95,\n",
    "                \"top_k\": 40,\n",
    "                \"max_output_tokens\": 8192,\n",
    "            }\n",
    "\n",
    "            model = genai.GenerativeModel(\n",
    "                model_name=\"gemini-1.5-pro-latest\",\n",
    "                generation_config=generation_config,\n",
    "                system_instruction=self.get_system_prompt()\n",
    "            )\n",
    "            \n",
    "            self.chat_session = model.start_chat(history=[])\n",
    "            self.add_to_chat(\"System\", \"AI Expert ready. Ask me anything about artificial intelligence!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to initialize model: {str(e)}\")\n",
    "\n",
    "    def get_system_prompt(self):\n",
    "        return \"\"\"You are an AI expert with 15+ years experience. Your responses should:\n",
    "        - Explain concepts clearly with analogies\n",
    "        - Differentiate between research and practical applications\n",
    "        - Highlight ethical considerations\n",
    "        - Acknowledge limitations of current AI\n",
    "        - Use examples from real-world implementations\n",
    "        - Adapt technical depth to user's level\"\"\"\n",
    "\n",
    "    def send_message(self):\n",
    "        message = self.user_input.get().strip()\n",
    "        if not message:\n",
    "            return\n",
    "            \n",
    "        self.user_input.delete(0, tk.END)\n",
    "        self.add_to_chat(\"You\", message)\n",
    "        \n",
    "        if not self.chat_session:\n",
    "            messagebox.showwarning(\"Warning\", \"API key not configured!\")\n",
    "            return\n",
    "            \n",
    "        threading.Thread(target=self.process_message, args=(message,)).start()\n",
    "\n",
    "    def process_message(self, message):\n",
    "        try:\n",
    "            response = self.chat_session.send_message(message)\n",
    "            self.add_to_chat(\"AI Expert\", response.text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.add_to_chat(\"Error\", str(e))\n",
    "\n",
    "    def add_to_chat(self, sender, message):\n",
    "        self.chat_display.config(state='normal')\n",
    "        self.chat_display.insert(tk.END, f\"{sender}: {message}\\n\\n\")\n",
    "        self.chat_display.yview(tk.END)\n",
    "        self.chat_display.config(state='disabled')\n",
    "\n",
    "    def show_api_key_dialog(self):\n",
    "        dialog = tk.Toplevel(self.root)\n",
    "        dialog.title(\"API Key Configuration\")\n",
    "        \n",
    "        ttk.Label(dialog, text=\"Enter Gemini API Key:\").pack(pady=5)\n",
    "        api_entry = ttk.Entry(dialog, width=40)\n",
    "        api_entry.pack(pady=5)\n",
    "        \n",
    "        def save_key():\n",
    "            self.api_key = api_entry.get().strip()\n",
    "            os.environ[\"GEMINI_API_KEY\"] = self.api_key\n",
    "            self.initialize_model()\n",
    "            dialog.destroy()\n",
    "            \n",
    "        ttk.Button(dialog, text=\"Save\", command=save_key).pack(pady=10)\n",
    "\n",
    "    def clear_history(self):\n",
    "        self.chat_display.config(state='normal')\n",
    "        self.chat_display.delete(1.0, tk.END)\n",
    "        self.chat_display.config(state='disabled')\n",
    "        self.chat_session.history.clear()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = GeminiChatApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab05c07",
   "metadata": {},
   "source": [
    "# Voice Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d30dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import threading\n",
    "import io\n",
    "\n",
    "class VoiceChangerApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        root.title(\"AI Voice Changer\")\n",
    "        root.geometry(\"900x700\")\n",
    "        \n",
    "        self.audio_file = None\n",
    "        self.modified_audio = None\n",
    "        self.create_widgets()\n",
    "        self.setup_audio_processing()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        main_frame = ttk.Frame(self.root, padding=15)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Chat Section\n",
    "        self.chat_history = tk.Text(main_frame, wrap=tk.WORD, state=tk.DISABLED)\n",
    "        self.chat_history.pack(fill=tk.BOTH, expand=True, pady=10)\n",
    "\n",
    "        # Audio Controls\n",
    "        control_frame = ttk.Frame(main_frame)\n",
    "        control_frame.pack(fill=tk.X, pady=10)\n",
    "\n",
    "        ttk.Button(control_frame, text=\"Load Audio\", command=self.load_audio).pack(side=tk.LEFT)\n",
    "        ttk.Button(control_frame, text=\"Preview\", command=self.preview_audio).pack(side=tk.LEFT)\n",
    "        ttk.Button(control_frame, text=\"Save\", command=self.save_audio).pack(side=tk.LEFT)\n",
    "\n",
    "        # Voice Parameters\n",
    "        param_frame = ttk.Frame(main_frame)\n",
    "        param_frame.pack(fill=tk.X)\n",
    "        \n",
    "        self.pitch_shift = ttk.Scale(param_frame, from_=-5, to=5, value=0)\n",
    "        self.pitch_shift.pack(side=tk.LEFT, expand=True)\n",
    "        ttk.Label(param_frame, text=\"Pitch Shift\").pack(side=tk.LEFT)\n",
    "\n",
    "        # Chat Input\n",
    "        input_frame = ttk.Frame(main_frame)\n",
    "        input_frame.pack(fill=tk.X)\n",
    "        \n",
    "        self.user_input = ttk.Entry(input_frame)\n",
    "        self.user_input.pack(side=tk.LEFT, fill=tk.X, expand=True)\n",
    "        ttk.Button(input_frame, text=\"Send\", command=self.process_input).pack(side=tk.LEFT)\n",
    "\n",
    "    def setup_audio_processing(self):\n",
    "        self.audio_data = None\n",
    "        self.sample_rate = 44100\n",
    "\n",
    "    def load_audio(self):\n",
    "        filetypes = [(\"Audio Files\", \"*.wav *.mp3 *.ogg\")]\n",
    "        file_path = filedialog.askopenfilename(filetypes=filetypes)\n",
    "        if file_path:\n",
    "            self.audio_file = file_path\n",
    "            self.audio_data, self.sample_rate = librosa.load(file_path, sr=None)\n",
    "            self.add_to_chat(\"System\", f\"Loaded audio: {file_path}\")\n",
    "\n",
    "    def process_audio(self):\n",
    "        if self.audio_data is None:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Basic pitch shifting\n",
    "            pitch_factor = 2 ** (self.pitch_shift.get() / 12)\n",
    "            modified = librosa.effects.pitch_shift(\n",
    "                y=self.audio_data,\n",
    "                sr=self.sample_rate,\n",
    "                n_steps=self.pitch_shift.get()\n",
    "            )\n",
    "            \n",
    "            # Add voice effect\n",
    "            self.modified_audio = self.apply_vocal_effect(modified)\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Processing Error\", str(e))\n",
    "\n",
    "    def apply_vocal_effect(self, audio):\n",
    "        # Add basic effects\n",
    "        audio = audio * 1.2  # Amplify\n",
    "        audio = librosa.effects.preemphasis(audio)\n",
    "        return audio\n",
    "\n",
    "    def preview_audio(self):\n",
    "        if self.modified_audio is not None:\n",
    "            import sounddevice as sd\n",
    "            sd.play(self.modified_audio, self.sample_rate)\n",
    "            sd.wait()\n",
    "\n",
    "    def save_audio(self):\n",
    "        if self.modified_audio is not None:\n",
    "            file_path = filedialog.asksaveasfilename(\n",
    "                defaultextension=\".wav\",\n",
    "                filetypes=[(\"WAV Files\", \"*.wav\")]\n",
    "            )\n",
    "            if file_path:\n",
    "                sf.write(file_path, self.modified_audio, self.sample_rate)\n",
    "                self.add_to_chat(\"System\", f\"Saved modified audio: {file_path}\")\n",
    "\n",
    "    def process_input(self):\n",
    "        user_text = self.user_input.get()\n",
    "        self.user_input.delete(0, tk.END)\n",
    "        self.add_to_chat(\"You\", user_text)\n",
    "        \n",
    "        threading.Thread(target=self.generate_response, args=(user_text,)).start()\n",
    "\n",
    "    def generate_response(self, prompt):\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model='mannix/gemma2-9b-simpo',\n",
    "                messages=[{\n",
    "                    'role': 'user',\n",
    "                    'content': f\"\"\"As a voice processing AI, analyze this request: \"{prompt}\"\n",
    "                    Respond with JSON containing:\n",
    "                    - \"pitch_shift\": recommended pitch change in semitones (-5 to 5)\n",
    "                    - \"effects\": list of suggested effects\n",
    "                    - \"message\": brief explanation\"\"\"\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            self.handle_ai_response(response['message']['content'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.add_to_chat(\"Error\", str(e))\n",
    "\n",
    "    def handle_ai_response(self, response):\n",
    "        try:\n",
    "            # Basic response parsing (implement proper JSON parsing)\n",
    "            if \"pitch_shift\" in response:\n",
    "                pitch_value = float(response.split(\"pitch_shift\")[1].split(\":\")[1].split(\",\")[0])\n",
    "                self.pitch_shift.set(pitch_value)\n",
    "                \n",
    "            self.process_audio()\n",
    "            self.add_to_chat(\"AI\", response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.add_to_chat(\"Error\", f\"Failed to parse response: {str(e)}\")\n",
    "\n",
    "    def add_to_chat(self, sender, message):\n",
    "        self.chat_history.config(state=tk.NORMAL)\n",
    "        self.chat_history.insert(tk.END, f\"{sender}: {message}\\n\\n\")\n",
    "        self.chat_history.yview(tk.END)\n",
    "        self.chat_history.config(state=tk.DISABLED)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = VoiceChangerApp(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
